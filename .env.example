# Event Hub Namespace (replace with your actual namespace)
EVENTHUB_NAMESPACE=<your-eventhub-namespace>

# Topic configurations - map to payload directories
EVENTHUBNAME_1=<your-eventhub-name>
EVENTHUBNAME_1_CONSUMER_GROUP=<your-consumer-group>

# MotherDuck Connection Settings (for control table)
MOTHERDUCK_TOKEN=<your-motherduck-token>
MOTHERDUCK_DATABASE=<your-motherduck-database>
TARGET_DB=<your-target-database>
TARGET_SCHEMA=<your-target-schema>
TARGET_TABLE=<your-target-table>

# MotherDuck ingestion configuration for EventHub topic1
MOTHERDUCK_1_DATABASE=<your-ingest-database>
MOTHERDUCK_1_SCHEMA=<your-ingest-schema>
MOTHERDUCK_1_TABLE=<your-ingest-table>
MOTHERDUCK_1_TOKEN=<your-ingest-token>
MOTHERDUCK_1_BATCH=<your-ingest-batch-size>

# Mapping configuration (for reference only)
# EVENTHUBNAME_1 -> MOTHERDUCK_1

# Smart Retry Configuration (Optional - used with --smart flag)
# These settings enable LLM-powered analysis of exceptions to decide if operations should be retried
SMART_RETRY_ENABLED=false
SMART_RETRY_LLM_PROVIDER=openai                    # openai, azure, anthropic, gemini, groq, cohere
SMART_RETRY_LLM_MODEL=gpt-4o-mini                 # Cost-effective model for retry decisions
SMART_RETRY_LLM_API_KEY=sk-your-api-key-here       # Required when using --smart flag
SMART_RETRY_LLM_ENDPOINT=                          # Optional: Custom endpoint (e.g., Azure OpenAI endpoint)
SMART_RETRY_MAX_ATTEMPTS=3                         # Maximum retry attempts (1-10)
SMART_RETRY_TIMEOUT_SECONDS=10                     # Timeout for LLM analysis (1-60 seconds)
SMART_RETRY_ENABLE_CACHING=true                    # Cache LLM decisions for similar errors

# Example Azure OpenAI Configuration:
# SMART_RETRY_LLM_PROVIDER=azure
# SMART_RETRY_LLM_MODEL=gpt-4o-mini
# SMART_RETRY_LLM_API_KEY=your-azure-api-key
# SMART_RETRY_LLM_ENDPOINT=https://your-resource.cognitiveservices.azure.com/openai/responses?api-version=2025-04-01-preview

# Logfire Observability Configuration (Optional)
# Get your token from https://logfire.pydantic.dev
LOGFIRE_ENABLED=false
LOGFIRE_TOKEN=your-logfire-token-here
LOGFIRE_SERVICE_NAME=streamduck
LOGFIRE_ENVIRONMENT=development
LOGFIRE_SEND_TO_LOGFIRE=true    # Send to Logfire cloud (requires token)
LOGFIRE_CONSOLE_LOGGING=true    # Keep Rich console output
LOGFIRE_LOG_LEVEL=INFO          # DEBUG, INFO, WARNING, ERROR, CRITICAL

# Example Production Configuration:
# LOGFIRE_ENABLED=true
# LOGFIRE_TOKEN=your-production-token
# LOGFIRE_SERVICE_NAME=streamduck-prod
# LOGFIRE_ENVIRONMENT=production
# LOGFIRE_SEND_TO_LOGFIRE=true
# LOGFIRE_CONSOLE_LOGGING=false
# LOGFIRE_LOG_LEVEL=WARNING

